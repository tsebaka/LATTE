defaults:
  - _self_
  - dataset_unsupervised/parquet
  - inference/default
  - inference/seq_encoder/pretrained

seed_everything: 42
logger_name: sop_model
model_path: models/sop_model.p
embed_file_name: sop_embeddings

data_module:
  _target_: ptls.frames.PtlsDataModule
  train_data:
    _target_: ptls.frames.bert.SopDataset
    splitter:
      _target_: ptls.frames.coles.split_strategy.SampleSlices
      split_count: 4
      cnt_min: 200
      cnt_max: 500
    data: ${dataset_unsupervised.train}
  valid_data:
    _target_: ptls.frames.bert.SopDataset
    splitter:
      _target_: ptls.frames.coles.split_strategy.SampleSlices
      split_count: 4
      cnt_min: 200
      cnt_max: 500
    data: ${dataset_unsupervised.valid}
  train_batch_size: 256
  train_num_workers: 8
  valid_batch_size: 1024
  valid_num_workers: 16

trainer:
  gpus: 1
  auto_select_gpus: false
  max_epochs: 100
  deterministic: true

pl_module:
  _target_: ptls.frames.bert.SopNspModule
  seq_encoder:
    _target_: ptls.nn.RnnSeqEncoder
    trx_encoder:
      _target_: ptls.nn.TrxEncoder
      norm_embeddings: false
      embeddings_noise: 0.003
      embeddings: 
        event_id: 
          in: 500
          out: 16
        event_code: 
          in: 50
          out: 8
        event_type: 
          in: 6
          out: 8
        title: 
          in: 50
          out: 8
        world: 
          in: 6
          out: 8
        correct: 
          in: 4
          out: 2
      numeric_values: {}
    type: gru
    hidden_size: 100
    bidir: false
    trainable_starter: static
  hidden_size: 512
  drop_p: 0.5
  optimizer_partial:
    _partial_: true
    _target_: torch.optim.Adam
    lr: 0.001
    weight_decay: 0.0
  lr_scheduler_partial:
    _partial_: true
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    mode: max
    patience: 15
    threshold: 0.001
    min_lr: 1e-6
    verbose: true
